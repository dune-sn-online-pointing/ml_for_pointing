{
  "description": "Three-plane with attention mechanism and diverse architectures - v5",
  "version": "v5_attention",
  
  "matched_data_file": "/eos/user/e/evilla/dune/sn-tps/production_es/three_plane_matched_50k.npz",
  "output_dir": "/afs/cern.ch/work/e/evilla/private/dune/ml_for_pointing/training_output/electron_direction",
  "model_name": "three_plane_attention_v5",
  
  "loss_function": "cosine",
  
  "dataset_parameters": {
    "train_fraction": 0.7,
    "val_fraction": 0.15,
    "test_fraction": 0.15,
    "shuffle_data": true,
    "random_seed": 42
  },
  
  "hyperopt_parameters": {
    "max_trials": 20,
    "epochs_per_trial": 100,
    "batch_size": 64,
    "early_stopping_patience": 15,
    
    "search_space": {
      "n_conv_layers": [3, 4, 5],
      "n_filters": [16, 32, 64, 128],
      "kernel_size": [3, 5, 7],
      "n_dense_layers": [1, 2, 3],
      "dense_units": [256, 512, 1024],
      "dropout_rate": [0.2, 0.3, 0.4, 0.5],
      "learning_rate": [0.0001, 0.0003, 0.0005, 0.001, 0.003]
    }
  }
}
