=========================================
HTCondor GPU Channel Tagging Training Job
=========================================
Job started at: Sun Nov  2 06:39:46 PM CET 2025
Running on host: b9g47n2453.cern.ch
Plane: X
Max samples: all
JSON config: /afs/cern.ch/work/e/evilla/private/dune/ml_for_pointing/json/channel_tagging/production_training.json
=========================================
Setting up LCG environment: LCG_106_cuda/x86_64-el9-gcc11-opt
Using LCG Python: /cvmfs/sft.cern.ch/lcg/views/LCG_106_cuda/x86_64-el9-gcc11-opt/bin/python3
Python 3.11.9


GPU Information:
Sun Nov  2 18:39:52 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla T4                       Off |   00000000:08:00.0 Off |                    0 |
| N/A   44C    P8             16W /   70W |      37MiB /  15360MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

Python version: Python 3.11.9
Python path: /cvmfs/sft.cern.ch/lcg/views/LCG_106_cuda/x86_64-el9-gcc11-opt/bin/python3
Checking TensorFlow...
2025-11-02 18:39:58.977988: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-02 18:40:08.176338: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
TensorFlow version: 2.16.1
2025-11-02 18:40:17.718770: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-11-02 18:40:21.278285: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-11-02 18:40:21.280875: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
GPUs detected: 1
  - /physical_device:GPU:0

Running: ./scripts/train_channel_tagging.sh -j /afs/cern.ch/work/e/evilla/private/dune/ml_for_pointing/json/channel_tagging/production_training.json --plane X
=========================================
âœ“ Sourced LCG environment: LCG_106_cuda/x86_64-el9-gcc11-opt
âœ“ Added local packages to PYTHONPATH
[0;34m[INFO][0m ML for Pointing Environment
[0;34m[INFO][0m Repository: /afs/cern.ch/work/e/evilla/private/dune/ml_for_pointing
[0;34m[INFO][0m Python modules: /afs/cern.ch/work/e/evilla/private/dune/ml_for_pointing/python
[0;34m[INFO][0m Data directory: /eos/home-e/evilla/dune/sn-tps/images_test
[0;34m[INFO][0m Output directory: /eos/user/e/evilla/dune/sn-tps/neural_networks
[0;34m[INFO][0m Python version: 3.11.9
[0;32m[SUCCESS][0m TensorFlow 2.16.1 is available
[INFO] ML for Pointing Environment
[INFO] Repository: /afs/cern.ch/work/e/evilla/private/dune/ml_for_pointing
[INFO] Python modules: /afs/cern.ch/work/e/evilla/private/dune/ml_for_pointing/python
[INFO] Data directory: /eos/home-e/evilla/dune/sn-tps/images_test
[INFO] Output directory: 
[INFO] Python version: 3.11.9
[SUCCESS] TensorFlow 2.16.1 is available
[INFO] Starting Channel Tagging Classifier Training
[INFO] Configuration: /afs/cern.ch/work/e/evilla/private/dune/ml_for_pointing/json/channel_tagging/production_training.json
[INFO] Running training script...
[INFO] Command: python3 ct_training.py --input_json /afs/cern.ch/work/e/evilla/private/dune/ml_for_pointing/json/channel_tagging/production_training.json --plane X


======================================================================
MAIN TRACK IDENTIFIER TRAINING
======================================================================

âœ“ GPU is available: 1 device(s)
  GPU 0: /physical_device:GPU:0

Loading configuration from: /afs/cern.ch/work/e/evilla/private/dune/ml_for_pointing/json/channel_tagging/production_training.json
Configuration loaded successfully

Output directory: /eos/user/e/evilla/dune/sn-tps/neural_networks/mt_identifier/hyperopt_simple_cnn/plane_X/20251102_184126
Configuration saved to: /eos/user/e/evilla/dune/sn-tps/neural_networks/mt_identifier/hyperopt_simple_cnn/plane_X/20251102_184126/config.json
Arguments saved to: /eos/user/e/evilla/dune/sn-tps/neural_networks/mt_identifier/hyperopt_simple_cnn/plane_X/20251102_184126/args.json
Selected model: hyperopt_simple_cnn

======================================================================
STEP 1: DATA PREPARATION
======================================================================

============================================================
LOADING DATA FROM NPZ FILES
============================================================
Data directory: /eos/home-e/evilla/dune/sn-tps/images_test
Plane: X
Max samples: All
Found 1 batch file(s) for plane X (pattern: clusters_planeX_batch*.npz)
Loading clusters_planeX_batch0000.npz... loaded 331 samples (total: 331)

Total loaded: 331 samples from plane X
Image shape: (331, 128, 16)
Metadata shape: (331, 11)

============================================================
Dataset Statistics
============================================================
Total samples: 331

Marley events: 126 (38.1%)
Main tracks: 87 (26.3%)
Background: 244 (73.7%)

Interaction type:
  ES: 0 (0.0%)
  CC/UNKNOWN: 331 (100.0%)

Plane distribution:
  U: 0 (0.0%)
  V: 0 (0.0%)
  X: 0 (0.0%)
============================================================

Dataset shape after preprocessing: (331, 128, 16, 1)
Labels shape: (331,)
Unique labels: [0. 1.]

Balancing dataset using undersample...
Original distribution: 87 main tracks, 244 background
Balanced distribution: 87 main tracks, 87 background

Shuffling the dataset...
Dataset shuffled.

Saving sample images to /eos/user/e/evilla/dune/sn-tps/neural_networks/mt_identifier/hyperopt_simple_cnn/plane_X/20251102_184126/samples...
Sample images saved.

Splitting the dataset...
Training set: 121 samples
Validation set: 26 samples
Test set: 27 samples
============================================================
DATA PREPARATION COMPLETE
============================================================


======================================================================
STEP 2: MODEL TRAINING
======================================================================
Running the hyperparameter search...
  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]                                                      (31,)
  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]  0%|          | 0/10 [00:01<?, ?trial/s, best loss=?]


âœ— Error during training: Exception encountered when calling Sequential.call().

[1mInput 0 of layer "dense" is incompatible with the layer: expected axis -1 of input shape to have value 40320, but received input with shape (None, 1176)[0m

Arguments received by Sequential.call():
  â€¢ inputs=('tf.Tensor(shape=(None, 128, 16, 1), dtype=float32)', 'tf.Tensor(shape=(None,), dtype=float32)')
  â€¢ training=True
  â€¢ mask=('None', 'None')
