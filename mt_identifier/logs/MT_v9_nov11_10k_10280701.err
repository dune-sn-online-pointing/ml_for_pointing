2025-11-11 15:30:45.109483: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-11 15:30:45.153556: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-11 15:30:47.032377: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/afs/cern.ch/work/e/evilla/private/dune/refactor_ml/python/data_loader.py:90: UserWarning: Skipping corrupted file (0 bytes): /eos/user/e/evilla/dune/sn-tps/production_cc/cluster_images_nov11/prodmarley_nue_flat_cc_dune10kt_1x2x2_20250926T185227Z_gen_000869_supernova_g4_detsim_ana_2025-10-21T_094611Z_bg_matched_planeX.npz
  warnings.warn(f"Skipping corrupted file (0 bytes): {file_path}")
/afs/cern.ch/work/e/evilla/private/dune/refactor_ml/python/data_loader.py:90: UserWarning: Skipping corrupted file (0 bytes): /eos/user/e/evilla/dune/sn-tps/production_cc/cluster_images_nov11/prodmarley_nue_flat_cc_dune10kt_1x2x2_20250926T205442Z_gen_003859_supernova_g4_detsim_ana_2025-10-21T_094447Z_bg_matched_planeX.npz
  warnings.warn(f"Skipping corrupted file (0 bytes): {file_path}")
Traceback (most recent call last):
  File "/afs/cern.ch/work/e/evilla/private/dune/refactor_ml/mt_identifier/models/main_production.py", line 402, in <module>
    main()
  File "/afs/cern.ch/work/e/evilla/private/dune/refactor_ml/mt_identifier/models/main_production.py", line 326, in main
    train, val, test, history_dict = cl.prepare_data_from_multiple_npz(
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/afs/cern.ch/work/e/evilla/private/dune/refactor_ml/python/classification_libs.py", line 635, in prepare_data_from_multiple_npz
    dataset_img, metadata = dl.load_dataset_from_multiple_directories(
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/afs/cern.ch/work/e/evilla/private/dune/refactor_ml/python/data_loader.py", line 413, in load_dataset_from_multiple_directories
    images, metadata = load_dataset_from_directory(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/afs/cern.ch/work/e/evilla/private/dune/refactor_ml/python/data_loader.py", line 198, in load_dataset_from_directory
    images = np.concatenate(all_images, axis=0)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 2, the array at index 0 has size 32 and the array at index 834 has size 16
